\section{Learning function-valued functions}
In this section we show how to used \acs{OVK} in hand with the \acs{ORFF}
framework to learn function valued function. We focus on two application cases:
quantile regression and one-class classification.
\paragraph{}
\textbf{Quantile regression.} As we have seen in the introductory
\cref{ch:motivations}, a standard task in machine learning is to estimate the
conditional expectation $f(x)=\expectation_{\probability}[Y | X = x]$, where
$(X,Y)\sim\probability$ with some function belonging to a hypothesis space
$f\in\mathcal{F}$. Yet, many sensitive applications need more than the expected
valued of the relationship between random variables. To control the
\say{quality} of the predicted value from an input $x$, fields such as
economics, medicine, physics or social science require to have acces to the
different quantile to model the distribution around the mean $f(x)$ and
strengthen their analysis.
\paragraph{}
Here we are interested in learning and predicting simultaneously \emph{all} the
quantiles on a compact support of the scalar-valued random variable $Y|X$. We
place ourselve in the setting of conditional quantile regression by minimization
of the pinball loss \citep{koenker1978regression}
\begin{dmath*}
    L(x, f, y) = \max(\tau (f(x) - y), (\tau - 1) (f(x) - y)).
\end{dmath*}

\paragraph{}
\textbf{One-class classification.}

Pioneer work has been done by
\citet{kadri2015operator},


\subsubsection{One class SVM revisited}

\subsubsection{Many quantile regression}
% %----------------------------------------------------------------------------
% \section{The Nystr\"om method}
% \label{sec:the_nystrom_method}

% %----------------------------------------------------------------------------
% \section{Sub-sampling the data}
% \label{sec:sub_sampling_the_data}
\section{Neural networks, deep learning}

\section{Operalib}
\url{https://github.com/operalib/operalib}
