% Colophon (a brief description of publication or production notes relevant to the edition)

\pagestyle{empty}

\pdfbookmark[0]{Colophon}{colophon}

\setlength{\fboxsep}{5mm}
\areaset
  {\textwidth}% calculate requiered \textwidth
  {\dimexpr\the\paperheight-0.cm\relax}% calculate requiered \textheight

\begin{textblock}{1}(1.5, .5)
\includegraphics[scale=.75]{../gfx/STIC.png} %% Logo de Paris Saclay
\end{textblock}

\begin{addmargin}[-.5cm]{-2.5cm}
\footnotesize

\vspace*{1.cm}
\noindent\color{PSaclay}\fbox{\parbox{\linewidth-2\fboxrule-2\fboxsep}{\normalcolor\vspace*{-.25cm}
\begin{center}
\textbf{\spacedlowsmallcaps{\mySubtitle}}
\end{center}
\paragraph{\textbf{Keywords:}} Operator-Valued Kernels, Large Scale Learning, Random Fourier Features
\begin{multicols}{2}
\paragraph{\textbf{Abstact:}} Many problems in Machine Learning can be cast into vector-valued functions approximation. Operator-Valued Kernels \emph{\acl{OVK}s} and vector-valued Reproducing Kernel Hilbert Spaces provide a theoretical and practical framework to address that issue, extending nicely the well-known setting of scalar-valued kernels. However large scale applications are usually not affordable with these tools that require an important computational power along with a large memory capacity. In this thesis, we propose and study scalable methods to perform regression with \emph{\acl{OVK}s}. To achieve this goal, we extend Random Fourier Features, an approximation technique originally introduced for scalar-valued kernels, to \emph{\acl{OVK}s}. The idea is to take advantage of an approximated operator-valued feature map in order to come up with a linear model in a finite-dimensional space.
\paragraph{}
This thesis is structured as follows. First we develop a general framework devoted to the approximation of shift-invariant Mercer kernels on Locally Compact Abelian groups and study their properties along with the complexity of the algorithms based on them. Second we show theoretical guarantees by bounding the error due to the approximation, with high probability. Third, we study various applications of Operator Random Fourier Features (\acs{ORFF}) to different tasks of Machine learning such as multi-class classification, multi-task learning, time serie modeling, functional regression and anomaly detection. We also compare the proposed framework with other state of the art methods. Fourth, we conclude by drawing short-term and mid-term perspectives of this work.
\end{multicols}\vspace*{-.5cm}}}
\vspace*{4mm}

\noindent\color{PSaclay}\fbox{\parbox{\linewidth-2\fboxrule-2\fboxsep}{\normalcolor\vspace*{-.35cm}
\begin{center}
\textbf{\spacedlowsmallcaps{R\'egression \`a noyaux \`a valeurs op\'erateurs pour grands ensembles de donn\'ees}}
\end{center}
\paragraph{\textbf{Mots clefs:}} Noyaux \`a Valeurs Op\'erateurs, Passage \`a l'\'echelle, Random Fourier Features
\begin{multicols}{2}
\paragraph{\textbf{R\'esum\'e:}} De nombreuses probl\'ematiques d'apprentissage artificiel peuvent \^etres mod\'elis\'es gr\^ace \`a des fonctions \`a valeurs vectorielles. Les \emph{noyaux \`a valeurs op\'erateurs} et leur espace de Hilbert \`a noyaux reproduisant \`a valeurs vectorielles associ\'es donnent un cadre th\'eorique et pratique pour apprendre de telles fonctions, \'etendant la litt\'erature existante des noyaux scalaires. Cependant, lorsque les donn\'ees sont nombreuses, ces m\'ethodes sont peu utilisables, ne passant pas \`a l'\'echelle, car elle n\'ec\'essite une quantit\'e de m\'emoire \'evoluant quadratiquement et un temps de calcul \'evoluant cubiquement vis \`a  vis du nombre de donn\'ees, dans leur impl\'ementation la plus na\"ive. Afin de faire passer les \emph{noyaux \`a valeurs op\'erateurs} \`a l'\'echelle, nous \'etendons une technique d'approximation stochastique introduite dans le cadres des noyaux scalaires. l'id\'ee est de tirer parti d'une fonction de redescription charact\'etisant le \emph{noyau \`a valeurs op\'erateurs}, dont les fonctions associ\'ees vivent dans un espace de dimension infinie, afin d'obtenir un probl\`eme d'optimisation lin\'eaire de dimension finie.
\paragraph{}
Dans cette th\`ese nous d\'eveloppons dans un premier temps un cadre g\'en\'eral afin de permettre l'approximation de noyaux de Mercer d\'efinits sur des groupes commutatifs localement compacts et \'etudions leurs propri\'et\'es ainsi que la complexit\'e des algorithmes en d\'ecoulant. Dans un second temps nous montrons des garanties th\'eoriques en bornant l'\'erreur comise par l'approximation, avec grande probabilit\'e. Enfin, nous mettons en \'evidence plusieurs applications des Repr\'esentations Op\'erateurs Al\'eatoires de Fourier (\acs{ORFF}) telles que la classification multiple, l'apprentissage multi-t\^ache, la mod\'elisation de s\'eries temporelles, la r\'egression fonctionelle et la d\'etection d'anomalies. Nous comparons \'egalement ce cadre avec d'autres m\'ethodes de la litt\'erature et concluons par des perspectives \`a moyen et long terme.
\end{multicols}\vspace*{-.5cm}}}

\vspace*{-2mm}
\normalcolor
\section*{Colophon}
\vspace*{-2mm}
\noindent This document was typeset using the typographical look-and-feel \texttt{cla\-ssic\-the\-sis} developed by Andr\'e Miede. The style was inspired by Robert Bringhurst's seminal book on typography ``\emph{The Elements of Typographic Style}''. \texttt{cla\-ssic\-the\-sis} is available at \url{https://bitbucket.org/amiede/classicthesis/} for both \LaTeX\ and \mLyX.
\paragraph{}
\vspace*{-2mm}
\noindent \color{PSaclay}\textbf{Universit\'e Paris-Saclay} \\
ED STIC -- 580 \\
Universit\'e Paris Sud, B\^atiment 650 Ada Lovelace, 91405 Orsay Cedex, France.

\begin{textblock}{13}(13.25,13.75)
\includegraphics[height=2cm]{../gfx/logoEgrey.png}
\end{textblock}

\end{addmargin}

