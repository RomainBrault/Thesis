%----------------------------------------------------------------------------------------
\section{Notations}
\label{sec:notations}
The euclidean inner product in $\mathbb{R}^d$ is denoted $\inner{\cdot, \cdot}$ and the euclidean norm is denoted $\norm{\cdot}$. The unit pure imaginary number $\sqrt{-1}$ is denoted $\iu$.
$\mathcal{B}(\mathbb{R}^d)$ is the Borel $\sigma$-algebra on $\mathbb{R}^d$.
If $\mathcal{X}$ and $\mathcal{Y}$ are two vector spaces, we denote by $\mathcal{F}(\mathcal{X};\mathcal{Y})$ the vector space of functions $f:\mathcal{X}\to\mathcal{Y}$ and $\mathcal{C}(\mathcal{X};\mathcal{Y})\subset\mathcal{F}(\mathcal{X};\mathcal{Y})$ the subspace of continuous functions.
If $\mathcal{H}$ is an Hilbert space we denote its scalar product by $\inner{\cdot,\cdot}_{\mathcal{H}}$ and its norm by $\norm{\cdot}_{\mathcal{H}}$.
We set $\mathcal{L}(\mathcal{H})=\mathcal{L}(\mathcal{H};\mathcal{H})$ to be the space of linear operators from $\mathcal{H}$ to itself. If $W\in\mathcal{L}(\mathcal{H})$, $\Ker W$ denotes the nullspace, $\Ima W$ the image and $W^\adjoint \in \mathcal{L}(\mathcal{H})$ the adjoint operator (transpose when $W$ is a real matrix). All these notations are summarized in \cref{table:notations}.

\begin{table}[!ht]
\centering
\caption{Mathematical symbols used throughout the parper and their signification.}
\begin{tabularx}{\textwidth}{cX}
\toprule
Symbol & \multicolumn{1}{c}{Meaning} \\
\cmidrule{1-2}
$\iu$ & Unit pure imaginary number $\sqrt{-1}$. \\
$\ec$ & Euler constant. \\
$\inner{\cdot,\cdot}$ & Euclidean inner product. \\
$\norm{\cdot}$ & Euclidean norm. \\
$\mathcal{X}$ & Input space (). \\
$\dual{\mathcal{X}}$ & The Pontryagin dual of $\mathcal{X}$. \\
$\mathcal{Y}$ & Output space (Hilbert space). \\
$\mathcal{H}$ & Feature space (Hilbert space). \\
$\inner{\cdot,\cdot}_{\mathcal{Y}}$ & The canonical inner product of the Hilbert space $\mathcal{Y}$. \\
$\norm{\cdot}_{\mathcal{Y}}$ & The canonical norm induced by the inner product of the Hilbert space $\mathcal{Y}$. \\
$\mathcal{F}(\mathcal{X};\mathcal{Y})$ & Vector space of function from $\mathcal{X}$ to $\mathcal{Y}$. \\
$\mathcal{C}(\mathcal{X};\mathcal{Y})$ & The vector subspace of $\mathcal{F}$ of continuous function from $\mathcal{X}$ to $\mathcal{Y}$. \\
$\mathcal{L}(\mathcal{H};\mathcal{Y})$ & The set of bounded linear operator from a Hilbert space $\mathcal{H}$ to a Hilbert space $\mathcal{Y}$. \\
$\mathcal{L}(\mathcal{Y})$ & The set of bounded linear operator from a Hilbert space $\mathcal{H}$ to itself. \\
$\mathcal{L}_{+}(\mathcal{Y})$ & The set of non-negative bounded linear operator from a Hilbert space $\mathcal{H}$ to itself. \\
$\mathcal{B}(\mathcal{X})$ & Borel $\sigma$-algebra on $\mathcal{X}$. \\
$\mu(\mathcal{X})$ & A scalar positive measure of $\mathcal{X}$. \\
$p_\mu(x)$ & The Radon-Nikodym derivative of $\mu$ \wrt~the Lebesgue measure. \\
$dx$, $d\omega$ & The canonical Haar measure of the \acs{LCA} group $(\mathcal{X},\mathcal{B}(\mathcal{X}))$. (resp. $(\dual{\mathcal{X}}, \mathcal{B}(\dual{\mathcal{X}})$). \\
$L^p(\mathcal{X},dx)$ & The Banach space of $\abs{\cdot}^p$-integrable function from $(\mathcal{X},\mathcal{B}(\mathcal{X}),dx)$ to $\mathbb{C}$. \\
$L^p(\mathcal{X},dx;\mathcal{Y})$ & The Banach space of  $\norm{\cdot}_{\mathcal{Y}^p}$ (Bochner)-integrable function from $(\mathcal{X},\mathcal{B}(\mathcal{X}), dx)$ to $\mathcal{Y}$. \\
\bottomrule
\end{tabularx}
\label{table:notations}
\end{table}

%----------------------------------------------------------------------------------------
\section{About statistical learning}
\label{sec:about_statistical_learning}

%----------------------------------------------------------------------------------------
\section{On large-scale learning}
\label{sec:on_large-scale_learning}

%----------------------------------------------------------------------------------------
\section{Elements of abstract harmonic analysis}
\label{sec:abstract_harmonic}

\subsection{Locally compact Abelian groups}
\begin{definition}{\acl{LCA} group.}
A group $(\mathcal{X}, \groupop)$ is said to be Locally Compact Abelian if it is a topological \emph{commutative} group $\mathcal{X}$ for which every point has a compact neighborhood and is Hausdorff. 
\end{definition}
\paragraph{}
\acf{LCA} groups are central to the general definition of Fourier Transform which is related to the concept of Pontryagin duality \citep{folland1994course}.
Let $(\mathcal{X}, \groupop)$ be a \acs{LCA} group with $e$ its neutral element and the notation, $\inv{x}$, for the inverse of $x \in \mathcal{X}$. A \emph{character} is a complex continuous homomorphism $\omega:\mathcal{X}\to\mathbb{U}$ from $\mathcal{X}$ to the set of complex numbers of unit module $\mathbb{U}$. The set of all characters of $\mathcal{X}$ forms the Pontryagin \emph{dual  group} $\dual{\mathcal{X}}$. The dual group of an \acs{LCA} group is an \acs{LCA} group and the dual group operation is defined by 
\begin{dmath*}
(\omega_1 \groupop \omega_2)(x)=\omega_1(x)\omega_2(x) \hiderel{\in} \mathbb{U}.
\end{dmath*}
\paragraph{}
The Pontryagin duality theorem states that $\dual{\dual{\mathcal{X}}}\cong \mathcal{X}$. \Ie~there is a canonical isomorphism between any \acs{LCA} group and its double dual. To emphasize this duality the following notation is usually adopted: $\omega(x)=\pairing{x,\omega}=\pairing{\omega,x}$, where $x\in\mathcal{X}$, $\omega\in\dual{\mathcal{X}}$. Another important property involves the complex conjugate of the pairing which is defined as $\conj{\pairing{x,\omega}} = \pairing{\inv{x},\omega}$.
\begin{table}[!ht]\label{table:pairings}
\caption{Classification of \acl{FT}s in terms of their domain and transform domain.}
\label{tab:dual_and_pairing}
\centering
\begin{tabularx}{\textwidth}{cccX}
\toprule
\multicolumn{1}{c}{$\mathcal{X}$} & \multicolumn{1}{c}{$\dual{\mathcal{X}}$} & \multicolumn{1}{c}{Operation} & \multicolumn{1}{c}{Pairing} \\
\cmidrule{1-4}
$\mathbb{R}^d$ & $\mathbb{R}^d$ & $+$ & $\pairing{x,\omega} = \exp\left(\iu \inner{x, \omega}\right)$ \\
$\mathbb{R}^d_{*,+}$ & $\mathbb{R}^d$ & $\cdot$ & $\pairing{x,\omega} =\exp\left( \iu \inner{\log(x), \omega} \right)$ \\
$(-c;+\infty)^d$ & $\mathbb{R}^d$ & $\odot$ & $\pairing{x,\omega} =\exp\left( \iu \inner{\log(x+c), \omega} \right)$ \\
\bottomrule
\end{tabularx}
\end{table}
\paragraph{}
We notice that for any pairing depending of $\omega$, there exists a function $h_{\omega}: \mathcal{X} \to \mathbb{R}$ such that: $(x,\omega)= \exp(-\iu h_{\omega}(x))$ since any pairing maps into $\mathbb{U}$. Moreover, 
\begin{dmath*}
(x \groupop \inv{z},\omega) \hiderel{=} \omega(x)\omega(\inv{z}) =\exp(-\iu h_{\omega}(x))\exp(-\iu h_{\omega}(\inv{z}))
=\exp(-\iu h_{\omega}(x))\exp(+\iu h_{\omega}(z)).
\end{dmath*}
\Cref{tab:dual_and_pairing} provide an explicit list of pairings for various groups based on $\mathbb{R}^d$ or its subsets. We especially mention the duality pairing associated to the skewed multiplicative \acs{LCA} group $\mathcal{X}=((-c;+\infty)^d, \odot)$
% where the operation $\odot$ is defined component-wise as follows:
% \begin{equation}
% \forall k\inrange{1}{d}, \enskip (x \odot z)_k \coloneq
 (x_k+c)(z_k+c) - c,
% \end{equation}
% Then the pairing is defined by:
% \begin{equation}\label{eq:pairing-skewed}
% \pairing{x, \omega} = \exp\left(i\sum_{k=1}^d\omega_k \log(x_k+c)\right).
% \end{equation}
Hence $h_\omega(x)=\sum_{k=1}^d\omega_k \log(x_k+c)$. This group together with the operation $\odot$ has  been proposed by \cite{li2010random} to handle histograms features especially useful in image recognition applications.
% % \begin{example}
% % $\dual{\mathbb{R}}\equiv\mathbb{R}$.
% % \begin{proof}
% % If $\omega\in\dual{\mathbb{R}}$ then $\omega(0)=1$ since $\omega$ is an homeomorphism from $\mathbb{R}$ to $\mathbb{U}$. Therefore there exists $a>0$ such that $\int_0^a\omega(t)dt\neq0$. Setting $A\omega=\int_0^a\omega(t)dt$ we have
% % \begin{equation*}
% % (A\omega)(x)=\int_0^a\omega(x+t)dt=\int_x^{a+x}\omega(t)dt.
% % \end{equation*}
% % so $\omega$ is differentiable and
% % \begin{equation*}
% % \omega'(x)=A^{-1}(\omega(a+x)-\omega(x))=c\omega(x) \quad\text{where}\quad c=A^{-1}(\omega(a)-1).
% % \end{equation*}
% % It follow that $\omega(x)=e^{cx}$, and since $\abs{\omega}=1$, one can take $c=i\omega$ for some $\omega\in\mathbb{R}$. Hence we can identify $\omega$ with $\omega$ and $\dual{\mathbb{R}}$ with $\mathbb{R}$ since $\omega$ uniquely determines $\omega$.
% % \end{proof}
% % \end{example}
\subsection{The Fourier transform}
For a function with values in a separable Hilbert space $f\in L^1(\mathcal{X},dx;\mathcal{Y})$, where $dx$ is the Haar measure on $\mathcal{X}$, we denote $\FT{f}$ its \acf{FT} which is defined by
\begin{dmath*}
    \forall \omega \in \dual{\mathcal{X}},\enskip \FT{f}(\omega) \hiderel{=}\int_{\dual{\mathcal{X}}} \conj{\pairing{x,\omega}}f(x)dx.
\end{dmath*} 
For a measure defined on $\mathcal{X}$, there exists a unique suitably normalized measure $d\omega$ on $\dual{\mathcal{X}}$ such that $\forall f \in L^1(\mathcal{X}, dx;\mathcal{Y})$ and if $\FT{f} \in L^1(\dual{\mathcal{X}}, d\omega, \mathcal{Y})$ we have
 \begin{dmath}\label{fourier-l1}
 \forall x \in \mathcal{X},\enskip f(x)\hiderel{=}\int_{\dual{\mathcal{X}}}\FT{f}(\omega)(x,\omega) d\omega.
\end{dmath}
Moreover if $d\omega$ is normalized, $\mathcal{F}$ extends to a unitary operator from $L^2(\mathcal{X}, dx, \mathcal{Y})$ onto $L^2(\dual{\mathcal{X}}, d\omega, \mathcal{Y})$ Then the \acf{IFT} of a function $g\in L^1(\dual{\mathcal{X}},d\omega,\mathcal{Y})$ (where $d\omega$ is a Haar measure on $\dual{\mathcal{X}}$ suitably normalize \wrt~the Haar measure $dx$) is noted $\IFT{g}$ defined by
\begin{dmath*}
    \forall x \in \mathcal{X},\enskip \IFT{g}(x) \hiderel{=} \int_{\dual{\mathcal{X}}} \pairing{x,\omega}g(\omega) d\omega,
\end{dmath*}
% The inverse Fourier transform of $g$, an integrable function on $\dual{X}$ is defined as:
% where the Haar measure $\mu=\dual{\nu}$ is called the {\it dual measure} to $\nu$.
\Cref{table:pairings} gives some examples of real Abelian groups with their associated dual and pairing. The interested reader can refer to \citet{folland1994course} for a more detailed construction of LCA, Pontryagin duality and \acl{FT}s on LCA. For the familiar case of a scalar-valued function $f$ on the \acs{LCA} group $(\mathbb{R}^d, +)$, we have: 
 \begin{dmath}\label{fourier-R-plus}
 \forall \omega \in \dual{\mathcal{X}},\enskip \FT{f}(\omega)\hiderel{=}\int_{\mathbb{R}^d} \ec^{-\iu \inner{\omega,x - z}}f(x) dx,
\end{dmath}
the Haar measure being here the Lebesgue measure.

%----------------------------------------------------------------------------------------
\section{On operator-valued kernels}
\label{sec:background_on_operator-valued_kernels}
We now introduce the theory of \acf{vv-RKHS} that provides a flexible framework to study and learn vector-valued functions.
\subsection{Definitions and properties}
\label{subsec:def_properties}
An operator-valued kernel is defined here as a $\mathcal{Y}$-reproducing kernel \citet{Carmeli2010}.
\begin{definition}
\label{def:reproducing_kernel}
Given $\mathcal{X}$ a Polish space and  $\mathcal{Y}$ a Hilbert Space, a map $K:\mathcal{X}\times\mathcal{X}\to\mathcal{L}(\mathcal{Y})$ is called a $\mathcal{Y}$-reproducing kernel if 
\begin{propenum}
\item $\sum_{i,j=1}^N\inner{K(x_i,x_j)y_j,y_i}_{\mathcal{Y}}\ge 0$,
for all $x_1,\hdots,x_N$ in $\mathcal{X}$, all $y_1,\hdots,y_N$ in $\mathcal{Y}$ and $N\ge 1$.
\item $K(x,z)=K(z,x)^\adjoint$ for all $x$, $z\in\mathcal{X}$.
\end{propenum}
\label{def:ovk}
\end{definition}
Given $x\in\mathcal{X}$, $K_x:\mathcal{Y}\to\mathcal{F}(\mathcal{X};\mathcal{Y})$ denotes the linear operator whose action on a vector $y$ is the function $K_xy\in\mathcal{F}(\mathcal{X};\mathcal{Y})$ defined for all $z\in\mathcal{X}$ by
\begin{dmath}
\label{eq:trivial_feature_op}
(K_x y)(z)=K(z,x)y.
\end{dmath}
\paragraph{}
Additionally, given a $\mathcal{Y}$-reproducing kernel $K$, there is a unique Hilbert space $\mathcal{H}_K\subset\mathcal{F}(\mathcal{X};\mathcal{Y})$ satisfying $K_x\in\mathcal{L}(\mathcal{Y};\mathcal{H}_K)$, for all $ x\in\mathcal{X}$ and $\forall x\in\mathcal{X}, \forall f\in\mathcal{H}_K, \enskip f(x)=K^\adjoint_x f$, where $K^\adjoint_x:\mathcal{H}_K\to\mathcal{Y}$ is the adjoint of $K_x$.
The space $\mathcal{H}_K$ is called the \emph{\acl{vv-RKHS}} associated with $K$. The corresponding product and norm are denoted by $\inner{.,.}_K$ and $\norm{.}_K$, respectively. As a consequence \citep{Carmeli2010} we have
\begin{dgroup}
\begin{dmath}
\label{eq:kernel_operator_product}
K(x,z)=K^\adjoint_x K_z \enskip\forall x,z\hiderel{\in}\mathcal{X}
\end{dmath},
\begin{dmath}
\label{eq:span_RKHS}
\mathcal{H}_K=\lspan\Set{ K_x y | \forall x\hiderel{\in}\mathcal{X},\enskip\forall y\hiderel{\in}\mathcal{Y} }.
\end{dmath}
\end{dgroup}
We note $\Set{K_{\mathcal{X}}\mathcal{Y}}\colonequals \Set{ K_x y | \forall x\hiderel{\in}\mathcal{X},\enskip\forall y\in\mathcal{Y} }$. Besides from \cref{eq:kernel_operator_product} we deduce that
\begin{dmath}
K(x,z)^\adjoint\hiderel{=}(K^\adjoint_x K_z)^\adjoint\hiderel{=}K^\adjoint_z K_x\hiderel{=}K(z,x).
\end{dmath}
Another way to describe functions of $\mathcal{H}_K$ consists in using a suitable feature map.
\begin{proposition}[Feature Operator \citep{Carmeli2010}]
\label{pr:feature_operator}
Let $\mathcal{H}$ be a Hilbert space and $\Phi:\mathcal{X}\to\mathcal{L}(\mathcal{Y};\mathcal{H})$, with $\Phi_x :=
 \Phi(x)$. Then the operator $W:\mathcal{H}\to\mathcal{F}(\mathcal{X};\mathcal{Y})$ defined for all $g \in\mathcal{H}$, and for all $x\in\mathcal{X}$ by $(W g)(x)=\Phi_x^\adjoint g$ is a partial isometry from $\mathcal{H}$ onto the \acs{vv-RKHS} $\mathcal{H}_K$ with reproducing kernel
\begin{dmath*}
K(x,z)=\Phi^\adjoint_x\Phi_z, \enskip \forall x, z\hiderel{\in}\mathcal{X}.
\end{dmath*}
$W^\adjoint W$ is the orthogonal projection onto 
\begin{dmath*}
  \Ker W^\bot = \lspan\Set{ \Phi_x y | \forall x\hiderel{\in}\mathcal{X},\enskip\forall y\hiderel{\in}\mathcal{Y} }.
\end{dmath*}
Then $\norm{f}_K=\inf\Set{ \norm{g}_{\mathcal{H}} | \forall g \in\mathcal{H},\enskip Wg=f }$.
\end{proposition}
We call $\Phi$ a \emph{feature map}, $W$ a \emph{feature operator} and $\mathcal{H}$ a \emph{feature space}. Since $W$ is a partial isometry from $(\ker W)^\bot$ onto $\mathcal{H}_K$, the map $W$ allows us to identify $\mathcal{H}_K$ with the closed subspace $(\ker W)^\bot$ of $\mathcal{H}$. With mild abuse of language, we say that $\mathcal{H}_K$ is embed into $\mathcal{H}$ by mean of the feature operator $W$. If we choose the trivial feature map $\Phi_x=K_x$ then the feature operator is the identity. In this work we mainly focus on the class kernels inducing a \acs{vv-RKHS} of continuous functions. Such kernels are named $\mathcal{Y}$-Mercer kernels.
\begin{definition}[$\mathcal{Y}$-Mercer kernel] A reproducing kernel $K:\mathcal{X}\times \mathcal{X}\to\mathcal{L}(\mathcal{Y})$ is called $\mathcal{Y}$-Mercer kernel if $\mathcal{H}_K$ is a subspace of $\mathcal{C}(\mathcal{X};\mathcal{Y})$.
\end{definition}
The following proposition characterize $\mathcal{Y}$-Mercer kernel in terms of the properties of a kernels rather than properties of the \acs{vv-RKHS}.
\begin{proposition}[Characterization of $\mathcal{Y}$-Mercer kernel \citep{Carmeli2010}] 
\label{pr:characterization_mercer_kernels}
Let $K$ be a reproducing kernel. The kernel $K$ is Mercer if and only if the function $x\mapsto\norm{K(x,x)}$ is locally bounded and for all $x\in\mathcal{X}$ and all $y\in\mathcal{Y}$, $K_xy\in\mathcal{C}(\mathcal{X};\mathcal{Y})$.
\end{proposition}
\begin{proof}
If $\mathcal{H}_K\subset\mathcal{C}(\mathcal{X};\mathcal{Y})$, then for all $x\in\mathcal{X}$ and all $y\in\mathcal{Y}$, $K_xy$ is an element of $\mathcal{C}(\mathcal{X};\mathcal{Y})$ (see \cref{eq:span_RKHS}). In addition for all $f\in\mathcal{H}_K$, $\norm{K_x}^\adjoint f$=$\norm{f(x)}\le \norm{f}_{\infty}$. Hence there exist a constant $M\in\mathbb{R}_+$ such that for all $x\in\mathcal{X}$, $\norm{K_x}\le M$. Therefore from \cref{eq:kernel_operator_product}, for all $x\in\mathcal{X}$, $\norm{K(x, x)}=\norm{K_x^\adjoint}^2\le M^2$. Conversely assume that the function $x\mapsto\norm{K(x,x)}$ is locally bounded and $K_xy\in\mathcal{C}(\mathcal{X};\mathcal{Y})$. For all $f\in\mathcal{H}_K$ and all $x\in\mathcal{X}$, 
\begin{dmath*}
\norm{f(x)}\hiderel{=}\norm{f}_K\sqrt{\norm{K(x,x)}}\hiderel{\le} M \norm{f}_K.
\end{dmath*}
Thus convergence in $\mathcal{H}_K$ implies uniform convergence. Since by assumption $\Set{K_{\mathcal{X}}\mathcal{Y}}\subset\mathcal{C}(\mathcal{X};\mathcal{Y})$, then the \acl{vv-RKHS} $\mathcal{H}_K=\lspan\Set{K_{\mathcal{X}}\mathcal{Y}}\subset\mathcal{C}$ is also a subset of $\mathcal{C}(\mathcal{X};\mathcal{Y})$ by the uniform convergence theorem.
\end{proof}

\begin{proposition}[Countable orthonormal basis for $\mathcal{Y}$-Mercer kernel \citep{carmeli2006vector}]
\label{pr:mercer_countable_basis}
Let $K:\mathcal{X}\times\mathcal{X}\to\mathcal{Y}$ be a reproducing kernel where $\mathcal{X}$ and $\mathcal{Y}$ are separable spaces. If $K$ is a $\mathcal{Y}$-Mercer kernel then $\mathcal{H}_K$ has a countable orthonormal basis.
\end{proposition}
\begin{proof}
From \cref{pr:characterization_mercer_kernels} $K$ is a $\mathcal{Y}$-Mercer kernel if and only if $\mathcal{H}_K\subset \mathcal{C}(\mathcal{X};\mathcal{Y})$. Applying corollary 3 of \cite{carmeli2006vector}, we have that $\mathcal{H}_K$ is separable. Thus since $\mathcal{H}_K$ is also a Hilbert space it has a countable orthonormal basis.
\end{proof}
An important consequence is that if $K$ is a $\mathcal{Y}$-Mercer and $\mathcal{X}$ and $\mathcal{Y}$ are separable then $\mathcal{H}_K$ is isometrically isomorphic to $\ell^2$.
%----------------------------------------------------------------------------------------
\subsection{Shift-Invariant operator-valued kernels}
The main subjects of interest of \cref{ch:operator-valued_random_fourier_features} are shift-invariant \acl{OVK}. When referring to a shift-invariant \acs{OVK} $K:\mathcal{X}\times\mathcal{X}\to\mathcal{L}(\mathcal{Y})$ we assume that $\mathcal{X}$ is a locally compact second countable topological group with identity
$e$.
\begin{definition}[Shift-invariant \acs{OVK}] A reproducing \acl{OVK} $K:\mathcal{X}\times\mathcal{X}\to\mathcal{L}(\mathcal{Y})$ is called shift-invariant\mpar{Also referred to as \emph{translation-invariant} \acs{OVK}.} if for all $x$, $z$, $t\in\mathcal{X}$, 
\begin{dmath}
\label{eq:def_shift_inv}
K(x\groupop t, z\groupop t) = K(x, z).
\end{dmath}
\end{definition}
A shift-invariant kernel can be characterize by a function of one variable $K_e$ called the signature of $K$. Here $e$ denotes the neutral element of the \acs{LCA} group $\mathcal{X}$ endowed with the operator $\groupop$.
\paragraph{}
To study shift-invariant kernels on \acs{LCA} groups we introduce the left regular representation of $\mathcal{X}$ acting on $\mathcal{H}_K$. For all $x$, $z\in\mathcal{X}$ and for all $f\in\mathcal{H}_K$,
\begin{dmath*}
(\lambda_z f)(x)\colonequals f(\inv{z}\groupop x).
\end{dmath*}
A group representation $\lambda_z$ describe the group by making it act on a vector space (here $\mathcal{H}_K$) in a linear manner. In other word, the group representation let us see a group as a linear operator which are well studied mathematical object.
\begin{proposition}[Kernel signature \citep{Carmeli2010}]
\label{pr:kernel_signature}
Let $K:\mathcal{X}\times\mathcal{X}\to\mathcal{L}(\mathcal{Y})$ be a reproducing kernel. The following conditions are equivalents.
\begin{propenum}
\item \label{pr:kernel_signature_1} $K$ is a shift-invariant reproducing kernel.
\item \label{pr:kernel_signature_2} There is a unique function $K_e:\mathcal{X}\to\mathcal{L}(\mathcal{Y})$ of completely positive type such that $K(x,z)=K_e(\inv{z}\groupop x)$.
\end{propenum}
If one of the above conditions is satisfied, then the representation $\lambda$ leaves invariant $\mathcal{H}_K$, its action on $\mathcal{H}_K$ is unitary and
\begin{dgroup}
\begin{dmath}
K(x,z)=K_e^\adjoint\lambda_{\inv{x}\groupop z}K_e \qquad \forall (x,z)\hiderel{\in}\mathcal{X}^2.
\end{dmath}
\begin{dmath}
\label{pr:kernel_signature_4}
\norm{K(x,x)}=\norm{K_e(e)} \qquad \forall x\hiderel{\in}\mathcal{X}
\end{dmath}
\end{dgroup}
\end{proposition}
\begin{proof} Assume \cref{pr:kernel_signature_1} holds true. Given $x$, $z\in\mathcal{X}$, \cref{eq:trivial_feature_op} and \cref{eq:def_shift_inv} yields
\begin{dmath*}
K_e(\inv{z}\groupop x)\hiderel{=}K(\inv{z} \groupop x,e)\hiderel{=}K(x,z).
\end{dmath*}
Since $K$ is a reproducing kernel, $K_e$ is of completely positive type, so that \cref{pr:kernel_signature_2} holds true. Besides if \cref{pr:kernel_signature_2} holds true obviously the definition of a reproducing kernel (\cref{def:reproducing_kernel}) is fulfilled so that \label{pr:kernel_signature_1} holds true. Finally let $K_e^1(x\groupop \inv{z})=K(x\groupop \inv{z},e)$ and $K_e^2(x\groupop \inv{z})=K(x\groupop \inv{z},e)$.
Obviously $K_e^1(x\groupop \inv{z})=K_e^2(x\groupop \inv{z})$ by transitivity of the relation equal.
\paragraph{}
Suppose that $K$ is a shift-invariant reproducing kernel. Given $t\in\mathcal{X}$ and $y\in\mathcal{Y}$, for all $x$, $z\in\mathcal{X}$,
\begin{dmath*}
(\lambda_xK_ty)(z)=(K_ty)(\inv{x}\groupop z)\hiderel{=}K(\inv{x}\groupop z,t)\hiderel{=}K(z,x\groupop t)\hiderel{=}(K_{x\groupop t}y)z,
\end{dmath*}
that is $\lambda_xK_t=K_{x\groupop t}$. Besides for all $y$, $y'\in\mathcal{Y}$ and all $x$, $z$, $t$, $t'\in\mathcal{X}$,
\begin{dmath*}
\inner{\lambda_xK_ty, \lambda_xK_{t'}y'}_K=\inner{K_{x\groupop t}y, K_{x \groupop t'}y'}_K\hiderel{=}\inner{K(x \groupop t', x \groupop t)y,y'}=\inner{K(t',t)y, y'}\hiderel{=}\inner{K_ty, K_{t'}y'}_K
\end{dmath*}
This mean that $\lambda$ leaves the set $\Set{K_{\mathcal{X}}\mathcal{Y}}$ invariant. 
Since $\Set{K_{\mathcal{X}}\mathcal{Y}}$ is total in $\mathcal{H}_K$ (see \cref{eq:span_RKHS}), $\lambda$ is surjective and because it also leaves the inner product invariant, the firs two claims follow.
\end{proof}
The notation $K_e$ for the function of completely positive type associated with the reproducing kernel $K$
is consistent with the definition given by \cref{eq:trivial_feature_op} since for all $x\in\mathcal{X}$ and all $y\in\mathcal{Y}$
\begin{dmath*}
(K_ey)(x)=K_e(x)y.
\end{dmath*}
\begin{lemma}[Shift-invariant $\mathcal{Y}$-Mercer kernels \citep{Carmeli2010}]
Let $K_e:\mathcal{X}\to\mathcal{Y}$ be a function of completely positive type and let $K$ be the corresponding translation invariant reproducing kernel. The following conditions are equivalent.
\begin{propenum}
\item The map $K$ is a $\mathcal{Y}$-Mercer kernel.
\item For all $y\in\mathcal{Y}$, $K_e(\cdot)y\in\mathcal{C}(\mathcal{X};\mathcal{Y})$.
\end{propenum}
\end{lemma}
\begin{proof}
The equivalence is a consequence of \cref{pr:characterization_mercer_kernels} observing that $(K_xy(z))=K_e(\inv{x}\groupop z)y$ and \cref{pr:kernel_signature} holds.
\end{proof}
Notice that if $K$ is a translation invariant kernel, \cref{pr:kernel_signature_4} implies that the elements of $\mathcal{H}_K$ are bounded functions. 
\begin{lemma}[\acl{FT} of shift-invariant $\mathcal{Y}$-Mercer kernels] 
\label{lm:fourier_shift_invariant}
Let $K_e:\mathcal{X}\to\mathcal{Y}$ be a function of completely positive type and let $K$ be the corresponding translation invariant reproducing kernel. If for all $y$, $y'\in\mathcal{Y}$, $\inner{y, K_e(\cdot)y'}\in L^1(\mathcal{X},dx)$ then
\begin{dmath}
\IFT{\inner{y, K_e(\cdot)y'}}=\FT{\inner{y, K_e(\cdot)^\adjoint y'}}.
\end{dmath}
\end{lemma}
\begin{proof}
For any function $f\in L^1(\mathcal{X},dx)$ define the flip operator $\mathcal{R}$ by
\begin{dmath*}
\mathcal{R}f(x) \colonequals f(\inv{x}).
\end{dmath*}
Then $\IFT{f}=\mathcal{R}\FT{f}=\mathcal{F}\mathcal{R}\left[f\right]$, so that we have $\IFT{\inner{y, K_e(\cdot)y'}}=\mathcal{F}\mathcal{R}{\inner{y, K_e(\cdot)y'}}$. For a shift-invariant kernel,
\begin{dmath*}
\mathcal{R}\inner{y,K_e(x\groupop \inv{z})y'}\hiderel{=}\inner{y,K_e(\inv{(x\groupop \inv{z})})y'}\hiderel{=}\inner{y,K_e(\inv{x}\groupop z)y'}=\inner{y,K_e(x\groupop \inv{z})^*y'}
\end{dmath*}
Thus $\IFT{\inner{y, K_e(\cdot)y'}}=\mathcal{F}\mathcal{R}\left[\inner{y,K_e(\cdot)y'}\right]=\FT{\inner{y, K_e(\cdot)^\adjoint y'}}$.
\end{proof}
There have been a lot of confusion in the literature whether a kernel is the \acl{FT} or \acl{IFT} of a measure. However \cref{lm:fourier_shift_invariant} clarify the relation between the \acl{FT} and \acl{IFT} for a translation invariant \acl{OVK}. Notice that in the real scalar case the \acl{FT} and \acl{IFT} of a shift-invariant kernel are the same, while the difference is significant for \acs{OVK}.

\subsection{Examples of operator-valued kernels}
\label{subsec:ovk-ex}
Operator-valued kernels have been first introduced in Machine Learning to solve multi-task regression problems. Multi-task regression is encountered in many fields such as structured classification when classes belong to a hierarchy for instance. Instead of solving independently $p$ single output regression task, one would like to take advantage of the relationships between output variables when learning and making a decision.  
\begin{definition}[Decomposable kernel]
\label{dec-kernel}
Let A be a positive semi-definite operator of $\mathcal{L}(\mathcal{Y})$. $K$ is said to be a $\mathcal{Y}$-Mercer \emph{decomposable} kernel\mpar{Some authors also refer to as \emph{separable} kernels.} if for all $(x,z) \in \mathcal{X}^2$, 
\begin{dmath*}
K(x,z) \colonequals k(x,z)A, 
\end{dmath*}
where $k$ is a \emph{scalar} Mercer kernel.
\end{definition}
When $\mathcal{Y}=\mathbb{R}^p$, the matrix $A$ is interpreted as encoding the relationships between the outputs coordinates. 
% This can easily be seen as a consequence of \cref{eq:reg_L2}.
% \begin{corollary}
% Let $K$ be a decomposable shift-invariant $\mathbb{R}^p$-Mercer Kernel such that $K_e(\cdot)_{\ell m}\in L^1(\mathcal{X}, dx)$. Define $BB^\adjoint p_\mu(\omega)\coloneq \IFT{K_e(\delta)}$. Then
% \begin{equation}
% \norm{f}^2_K=\displaystyle\sum_{\ell, m=1}^p A_{\ell m}^\dagger \int_{\dual{\mathcal{X}}}\frac{\inner{\FT{f_\ell}(\omega), \FT{f_m}(\omega)}_{\mathcal{Y}}}{p_\mu(\omega)}d\omega=\displaystyle\sum_{\ell, m=1}^p A_{\ell m}^\dagger \inner{f_\ell, f_m}_k.
% \end{equation}
% \end{corollary}
% \begin{proof}
% Apply \cref{pr:regularization} with $A(\omega)=A$.
% \end{proof}
% Where $\inner{\cdot}_k$ is the inner product induced by the scalar kernel $k$ in the RKHS $\mathcal{H}_k$. Hence we recover the result of \cite{Alvarez2012}. In particular 
If a graph coding for the proximity between tasks is known, then it is shown in \citet{Evgeniou2005,Baldassare2010,Alvarez2012} that $A$ can be chosen equal to the pseudo inverse $L^{\dagger}$ of the graph Laplacian such that the norm in $\mathcal{H}_K$ is a graph-regularizing penalty for the outputs (tasks).  When no prior knowledge is available, $A$ can be set to the empirical covariance of the output training data or learned with one of the algorithms proposed in the literature \citep{Dinuzzo2011, Sindhwani2013, Lim2015}. Another interesting property of the decomposable kernel is its universality (a kernel which may approximate an arbitrary continuous target function uniformly on any compact subset of the input space). A reproducing kernel $K$ is said \emph{universal} if the associated \acs{vv-RKHS} $\mathcal{H}_K$ is dense in the space $\mathcal{C}(\mathcal{X},\mathcal{Y})$. The conditions for a kernel to be universal have been discussed in \citet{caponnetto2008,Carmeli2010}. In particular they show that a decomposable kernel is universal provided that the scalar kernel $k$ is universal and the operator $A$ is injective.
\begin{proposition}[Kernels and Regularizers \citep{Alvarez2012}]
Let $K(x,z) \colonequals k(x,z)A$ for all $x$, $z\in\mathcal{X}$ be a decomposable kernel where $A$ is a matrix of size $p\times p$. Then for all $f\in\mathcal{H}_K$,
\begin{dmath}
\norm{f}_K = \sum_{i,j=1}^p A^\dagger_{ij}\inner{f_i,f_j}_k
\end{dmath}
where $f_i=\inner{f,e_i}$ (resp $f_j=\inner{f,e_j}$), denotes the $i$-th (resp $j$-th) component of $f$.
\end{proposition}

\paragraph{}  
Curl-free and divergence-free kernels provide an interesting application of operator-valued kernels \citep{Macedo2008, Baldassare2012, Micheli2013} to \emph{vector field} learning, for which input and output spaces have the same dimensions ($d=p$). %
Applications cover shape deformation analysis \citep{Micheli2013} and magnetic fields approximations \citep{Wahlstrom2013}. %
These kernels discussed in \citep{Fuselier2006} allow encoding input-dependent similarities between vector-fields. %
\begin{definition}[Curl-free and Div-free kernel]\label{curl-div-free}
Assume $\mathcal{X}=(\mathbb{R}^d, +)$ and $\mathcal{Y}=\mathbb{R}^p$ with $d=p$. %
The \emph{divergence-free} kernel is defined as %
\begin{dmath*}\label{div-def}
K^{div}(x,z)=K^{div}_0(\delta)
\hiderel{=} (\nabla\nabla^T - \Delta I) k_0(\delta)
\end{dmath*} %
and the \emph{curl-free} kernel as %
\begin{dmath*}\label{curl-def}
K^{curl}(x,z)\hiderel{=}K_0^{curl}(\delta)=-\nabla\nabla^T k_0(\delta),
\end{dmath*} %
where $\nabla\nabla^T$ is the Hessian operator and $\Delta$ is the Laplacian operator. %
\end{definition}
Although taken separately these kernels are not universal, a convex combination of the curl-free and divergence-free kernels allows to learn any vector field that satisfies the Helmholtz decomposition theorem \citep{Macedo2008, Baldassare2012}.

\chapterend
